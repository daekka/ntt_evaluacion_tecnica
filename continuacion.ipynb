{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      ID  var_1  var_2  var_3   var_4   var_5  var_6  var_7  \\\n",
      "0               2       3      2     34    0.0    0.00    0.00    0.0    0.0   \n",
      "1               7      14      2     27    0.0    0.00    0.00    0.0    0.0   \n",
      "2               8      18      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "3              10      23      2     25    0.0    0.00    0.00    0.0    0.0   \n",
      "4              12      26      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "...           ...     ...    ...    ...    ...     ...     ...    ...    ...   \n",
      "38062       43187   86463      2     36    0.0  176.79  176.79    0.0    0.0   \n",
      "38063       56100  111953      2     27    0.0    0.00    0.00    0.0    0.0   \n",
      "38064       43695   87523      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "38065        8115   16373      2     32    0.0    0.00    0.00    0.0    0.0   \n",
      "38066       51281  102362      2     23    0.0    0.00    0.00    0.0    0.0   \n",
      "\n",
      "       var_8  ...  var_362  var_363  var_364  var_365  var_366  var_367  \\\n",
      "0        0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1        0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "2        0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "3        0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "4        0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "...      ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "38062    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "38063    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "38064    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "38065    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "38066    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "       var_368        var_369   var_370  Target  \n",
      "0          0.0   49278.030000  0.012858       0  \n",
      "1          0.0   94956.660000  0.391089       0  \n",
      "2          0.0  251638.950000  0.300590       0  \n",
      "3          0.0  356463.060000  0.022430       0  \n",
      "4          0.0   75368.520000  0.004120       0  \n",
      "...        ...            ...       ...     ...  \n",
      "38062      0.0   58191.720000  0.053754       0  \n",
      "38063      0.0  117310.979016  0.146080       0  \n",
      "38064      0.0  131701.590000  0.010387       0  \n",
      "38065      0.0   72124.830000  0.275760       0  \n",
      "38066      0.0   58750.530000  0.210024       0  \n",
      "\n",
      "[38067 rows x 373 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unittest\n",
    "import pycaret\n",
    "src_train = pd.read_csv('data_train.csv', dtype={'ID': str})\n",
    "print (src_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Sobre la variables “var_370”, genera dos variables nuevas:\n",
    "    a. Aplicando el logaritmo con base mediana.\n",
    "    b. Normalizando dicha variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      ID  var_1  var_2  var_3   var_4   var_5  var_6  var_7  \\\n",
      "0               2       3      2     34    0.0    0.00    0.00    0.0    0.0   \n",
      "1               7      14      2     27    0.0    0.00    0.00    0.0    0.0   \n",
      "2               8      18      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "3              10      23      2     25    0.0    0.00    0.00    0.0    0.0   \n",
      "4              12      26      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "...           ...     ...    ...    ...    ...     ...     ...    ...    ...   \n",
      "38062       43187   86463      2     36    0.0  176.79  176.79    0.0    0.0   \n",
      "38063       56100  111953      2     27    0.0    0.00    0.00    0.0    0.0   \n",
      "38064       43695   87523      2     26    0.0    0.00    0.00    0.0    0.0   \n",
      "38065        8115   16373      2     32    0.0    0.00    0.00    0.0    0.0   \n",
      "38066       51281  102362      2     23    0.0    0.00    0.00    0.0    0.0   \n",
      "\n",
      "       var_8  ...  var_364  var_365  var_366  var_367  var_368        var_369  \\\n",
      "0        0.0  ...      0.0      0.0      0.0      0.0      0.0   49278.030000   \n",
      "1        0.0  ...      0.0      0.0      0.0      0.0      0.0   94956.660000   \n",
      "2        0.0  ...      0.0      0.0      0.0      0.0      0.0  251638.950000   \n",
      "3        0.0  ...      0.0      0.0      0.0      0.0      0.0  356463.060000   \n",
      "4        0.0  ...      0.0      0.0      0.0      0.0      0.0   75368.520000   \n",
      "...      ...  ...      ...      ...      ...      ...      ...            ...   \n",
      "38062    0.0  ...      0.0      0.0      0.0      0.0      0.0   58191.720000   \n",
      "38063    0.0  ...      0.0      0.0      0.0      0.0      0.0  117310.979016   \n",
      "38064    0.0  ...      0.0      0.0      0.0      0.0      0.0  131701.590000   \n",
      "38065    0.0  ...      0.0      0.0      0.0      0.0      0.0   72124.830000   \n",
      "38066    0.0  ...      0.0      0.0      0.0      0.0      0.0   58750.530000   \n",
      "\n",
      "        var_370  Target  var_370_log_med  var_370_norm  \n",
      "0      0.012858       0         1.796752      0.016827  \n",
      "1      0.391089       0         0.387437      0.512151  \n",
      "2      0.300590       0         0.496050      0.393636  \n",
      "3      0.022430       0         1.567114      0.029362  \n",
      "4      0.004120       0         2.266429      0.005384  \n",
      "...         ...     ...              ...           ...  \n",
      "38062  0.053754       0         1.206417      0.070384  \n",
      "38063  0.146080       0         0.793841      0.191292  \n",
      "38064  0.010387       0         1.884796      0.013592  \n",
      "38065  0.275760       0         0.531630      0.361119  \n",
      "38066  0.210024       0         0.644009      0.275031  \n",
      "\n",
      "[38067 rows x 375 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Función para aplicar logaritmo en base mediana\n",
    "def logaritmo_base_mediana(df, columna):\n",
    "    \n",
    "    mediana = df[columna].median()\n",
    "    if mediana <= 0:\n",
    "        raise ValueError(\"La mediana debe ser mayor que 0 para aplicar logaritmo.\")\n",
    "\n",
    "    df[columna + '_log_med'] = np.log(df[columna]) / np.log(mediana)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2. Función para normalizar una variable\n",
    "def normalizar_variable(df, columna, metodo=\"minmax\"):\n",
    "\n",
    "    if metodo == \"zscore\":\n",
    "        media = df[columna].mean()\n",
    "        std = df[columna].std()\n",
    "        df[columna + '_norm'] = (df[columna] - media) / std\n",
    "    \n",
    "    elif metodo == \"minmax\":\n",
    "        min_val = df[columna].min()\n",
    "        max_val = df[columna].max()\n",
    "        df[columna + '_norm'] = (df[columna] - min_val) / (max_val - min_val)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Método no válido. Usa 'zscore' o 'minmax'.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "src_train = logaritmo_base_mediana(src_train, \"var_370\")\n",
    "src_train = normalizar_variable (src_train, \"var_370\")\n",
    "print (src_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Construye una función que reciba una serie de datos (como puede ser una variable en un dataset) y devuelva esa serie normalizada entre 0 y 1. Además la función tiene que comprobar que el formato de la variable de entrada es una serie y elevar un error en caso contrario. Ejecuta esta función sobre la variable que consideres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.016827\n",
      "1        0.512151\n",
      "2        0.393636\n",
      "3        0.029362\n",
      "4        0.005384\n",
      "           ...   \n",
      "38062    0.070384\n",
      "38063    0.191292\n",
      "38064    0.013592\n",
      "38065    0.361119\n",
      "38066    0.275031\n",
      "Name: var_370, Length: 38067, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalizar_serie(serie):\n",
    "    if not isinstance(serie, pd.Series):\n",
    "        raise TypeError(\"La entrada debe ser una serie de Pandas\")\n",
    "    \n",
    "    min_val = serie.min()\n",
    "    max_val = serie.max()\n",
    "    \n",
    "    if min_val == max_val:\n",
    "        return serie.apply(lambda x: 0)  # Evita la división por cero en caso de valores constantes\n",
    "    \n",
    "    return (serie - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "data = pd.Series([10, 20, 30, 40, 50])\n",
    "serie_normalizada = normalizar_serie(src_train['var_370'])\n",
    "print (serie_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Genera los test unitarios que consideres para comprobar el funcionamiento correcto de la función anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcto\n",
      "Correcto\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "La entrada debe ser una serie de Pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# No serie\u001b[39;00m\n\u001b[0;32m     21\u001b[0m serie \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m]\n\u001b[1;32m---> 22\u001b[0m resultado \u001b[38;5;241m=\u001b[39m normalizar_serie(serie)\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mnormalizar_serie\u001b[1;34m(serie)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalizar_serie\u001b[39m(serie):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(serie, pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLa entrada debe ser una serie de Pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     min_val \u001b[38;5;241m=\u001b[39m serie\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m      6\u001b[0m     max_val \u001b[38;5;241m=\u001b[39m serie\u001b[38;5;241m.\u001b[39mmax()\n",
      "\u001b[1;31mTypeError\u001b[0m: La entrada debe ser una serie de Pandas"
     ]
    }
   ],
   "source": [
    "serie = pd.Series([10, 20, 30, 40, 50])\n",
    "resultado = normalizar_serie(serie)\n",
    "esperado = pd.Series([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "if resultado.equals(esperado):\n",
    "    print(\"Correcto\")\n",
    "else:\n",
    "    print(\"Incorrecto\")\n",
    "\n",
    "serie = pd.Series([5, 5, 5, 5])\n",
    "resultado = normalizar_serie(serie)\n",
    "esperado = pd.Series([0, 0, 0, 0])\n",
    "if resultado.equals(esperado):\n",
    "    print(\"Correcto\")\n",
    "else:\n",
    "    print(\"Incorrecto\")\n",
    "\n",
    "\n",
    "# No serie\n",
    "serie = [10, 20, 30, 40, 50]\n",
    "resultado = normalizar_serie(serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Genera un dataframe con las siguientes variables: 'ID', 'var_2', 'var_276', 'var_325', 'var_278', 'var_275', 'var_280', 'var_327', 'var_63', 'var_369', 'var_1', 'var_279', 'var_340', 'var_339', 'var_165', 'var_177', 'var_172', 'var_168', 'var_114', 'var_47', 'var_105', 'var_194', 'Target', además incluye las variables sintéticas generadas en la pregunta anterior.Guárdalo en un archivo csv que se llame vun_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    var_2_normalizada = normalizar_serie(src_train['var_2'])\n",
    "    columnas_seleccionadas = [\n",
    "        'ID', 'var_2', 'var_276', 'var_325', 'var_278', 'var_275', 'var_280', 'var_327',\n",
    "        'var_63', 'var_369', 'var_1', 'var_279', 'var_340', 'var_339', 'var_165', 'var_177',\n",
    "        'var_172', 'var_168', 'var_114', 'var_47', 'var_105', 'var_194', 'Target'\n",
    "    ]\n",
    "    \n",
    "    vun_train = src_train[columnas_seleccionadas].copy()\n",
    "    vun_train['var_2_normalizada'] = var_2_normalizada.values\n",
    "    vun_train.to_csv('vun_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bloque 4. Modelización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Vuelve a cargar el archivo vun_train.csv sobre la variable vun_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  var_2  var_276  var_325  var_278  var_275  var_280  var_327  \\\n",
      "0           3     34        0        0        0        0        0        0   \n",
      "1          14     27        0        0        0        0        0        0   \n",
      "2          18     26        0        0        0        0        0        0   \n",
      "3          23     25        0        0        0        0        0        0   \n",
      "4          26     26        0        0        0        0        0        0   \n",
      "...       ...    ...      ...      ...      ...      ...      ...      ...   \n",
      "38062   86463     36        0        9        3        3        9       27   \n",
      "38063  111953     27        0        0        0        0        0        0   \n",
      "38064   87523     26        0        0        0        0        0        0   \n",
      "38065   16373     32        0        0        0        0        0        0   \n",
      "38066  102362     23        0        0        0        0        0        0   \n",
      "\n",
      "       var_63        var_369  ...  var_165  var_177  var_172  var_168  \\\n",
      "0           1   49278.030000  ...     0.00      0.0    300.0      0.0   \n",
      "1           1   94956.660000  ...     3.00      0.0      0.0      0.0   \n",
      "2           1  251638.950000  ...     3.00      0.0      0.0      0.0   \n",
      "3           1  356463.060000  ...     3.00      0.0      0.0      0.0   \n",
      "4           1   75368.520000  ...     0.00      0.0      0.0      0.0   \n",
      "...       ...            ...  ...      ...      ...      ...      ...   \n",
      "38062       1   58191.720000  ...  4555.98      0.0      0.0      0.0   \n",
      "38063       1  117310.979016  ...    90.00      0.0      0.0      0.0   \n",
      "38064       1  131701.590000  ...     0.00      0.0      0.0      0.0   \n",
      "38065       1   72124.830000  ...     3.00      0.0      0.0      0.0   \n",
      "38066       1   58750.530000  ...    90.00      0.0      0.0      0.0   \n",
      "\n",
      "       var_114  var_47  var_105  var_194  Target  var_2_normalizada  \n",
      "0            0       0        3        3       0           0.298969  \n",
      "1            0       0        0        3       0           0.226804  \n",
      "2            0       0        0        2       0           0.216495  \n",
      "3            0       0        0        2       0           0.206186  \n",
      "4            0       0        0       99       0           0.216495  \n",
      "...        ...     ...      ...      ...     ...                ...  \n",
      "38062        0       0        0        2       0           0.319588  \n",
      "38063        0       0        0        3       0           0.226804  \n",
      "38064        0       0        0       99       0           0.216495  \n",
      "38065        0       0        0        3       0           0.278351  \n",
      "38066        0       0        0        3       0           0.185567  \n",
      "\n",
      "[38067 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "vun_train = pd.read_csv('vun_train.csv')\n",
    "vun_train = vun_train.iloc[:, 1:]\n",
    "print (vun_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Separa el dataframe vun_train en dos: uno de entrenamiento y otro de validación, con el 70% y el 30% de los registros respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "semilla = 183530\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# Dividir en entrenamiento (70%) y prueba (30%)\n",
    "train_df, test_df = train_test_split(vun_train, test_size=0.3, random_state=semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Realiza un modelo de regresión logística con las variables que consideres oportunas. Interpreta los resultados en función de los p-valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1af5b_row8_col1, #T_1af5b_row12_col1, #T_1af5b_row14_col1, #T_1af5b_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1af5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1af5b_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_1af5b_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1af5b_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_1af5b_row0_col1\" class=\"data row0 col1\" >183530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1af5b_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_1af5b_row1_col1\" class=\"data row1 col1\" >Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1af5b_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_1af5b_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1af5b_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_1af5b_row3_col1\" class=\"data row3 col1\" >(26646, 24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1af5b_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_1af5b_row4_col1\" class=\"data row4 col1\" >(25713, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1af5b_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_1af5b_row5_col1\" class=\"data row5 col1\" >(17719, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1af5b_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_1af5b_row6_col1\" class=\"data row6 col1\" >(7994, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1af5b_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_1af5b_row7_col1\" class=\"data row7 col1\" >23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1af5b_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_1af5b_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1af5b_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_1af5b_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1af5b_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_1af5b_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1af5b_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_1af5b_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1af5b_row12_col0\" class=\"data row12 col0\" >Remove outliers</td>\n",
       "      <td id=\"T_1af5b_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1af5b_row13_col0\" class=\"data row13 col0\" >Outliers threshold</td>\n",
       "      <td id=\"T_1af5b_row13_col1\" class=\"data row13 col1\" >0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1af5b_row14_col0\" class=\"data row14 col0\" >Normalize</td>\n",
       "      <td id=\"T_1af5b_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1af5b_row15_col0\" class=\"data row15 col0\" >Normalize method</td>\n",
       "      <td id=\"T_1af5b_row15_col1\" class=\"data row15 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1af5b_row16_col0\" class=\"data row16 col0\" >Feature selection</td>\n",
       "      <td id=\"T_1af5b_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1af5b_row17_col0\" class=\"data row17 col0\" >Feature selection method</td>\n",
       "      <td id=\"T_1af5b_row17_col1\" class=\"data row17 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1af5b_row18_col0\" class=\"data row18 col0\" >Feature selection estimator</td>\n",
       "      <td id=\"T_1af5b_row18_col1\" class=\"data row18 col1\" >lightgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1af5b_row19_col0\" class=\"data row19 col0\" >Number of features selected</td>\n",
       "      <td id=\"T_1af5b_row19_col1\" class=\"data row19 col1\" >0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_1af5b_row20_col0\" class=\"data row20 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_1af5b_row20_col1\" class=\"data row20 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_1af5b_row21_col0\" class=\"data row21 col0\" >Fold Number</td>\n",
       "      <td id=\"T_1af5b_row21_col1\" class=\"data row21 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_1af5b_row22_col0\" class=\"data row22 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_1af5b_row22_col1\" class=\"data row22 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_1af5b_row23_col0\" class=\"data row23 col0\" >Use GPU</td>\n",
       "      <td id=\"T_1af5b_row23_col1\" class=\"data row23 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_1af5b_row24_col0\" class=\"data row24 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_1af5b_row24_col1\" class=\"data row24 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_1af5b_row25_col0\" class=\"data row25 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_1af5b_row25_col1\" class=\"data row25 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1af5b_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_1af5b_row26_col0\" class=\"data row26 col0\" >USI</td>\n",
       "      <td id=\"T_1af5b_row26_col1\" class=\"data row26 col1\" >ecb5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c0c036ef20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Se usa PYCARET: librería low-code para aprendizaje automático\n",
    "# Configuración PYCARET\n",
    "from pycaret.regression import *\n",
    "s = setup(data = train_df, target = 'Target', session_id = semilla, normalize= True, remove_outliers = True, feature_selection = True, imputation_type = 'simple', numeric_imputation = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>13:04:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Orthogonal Matching Pursuit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           \n",
       "                                                                           \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                     13:04:09\n",
       "Status     . . . . . . . . . . . . . . . . . .             Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Orthogonal Matching Pursuit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cd6fcf823843eaaabc69cb24560f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare baseline models\n",
    "best = compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
